# Sprint 3 ‚Äì Hermes Reply / FIAP ‚Äî indusAI Innovations

> **Objetivo:** Modelar um banco de dados relacional para dados de sensores e treinar um modelo **b√°sico** de Machine Learning usando os dados da Sprint 2 (temperatura) **enriquecidos** com novos sensores simulados (**umidade, vibra√ß√£o RMS, corrente do motor, luminosidade, press√£o**). O r√≥tulo **estado_operacional** (normal/alerta/falha) foi calculado por regras simples e plaus√≠veis para o dom√≠nio industrial.

---

## Estrutura do reposit√≥rio
```
sprint3_pack/
  data/
    raw/
      sprint2_dados_temperatura.csv
    processed/
      dataset_sprint3_multisensor.csv      # ~2.400 leituras, 6 sensores + r√≥tulos
  db/
    schema_oracle.sql
    seed_data.sql
    erd.mmd
    ERD_sprint3_datasql.png                # DER exportado pelo Oracle Data Modeler
    prints/                                # evid√™ncias (DDL, seed, contagens etc.)
  src/
    ml_train_sprint3.py                    # classifica√ß√£o (normal/alerta/falha)
    ml_regression_sprint3.py               # regress√£o (b√¥nus): prever temp_c +5 min
  results/                                 # sa√≠das geradas pelos scripts de ML
  README.md
```

---

## ‚öôÔ∏è Prepara√ß√£o r√°pida (ambiente Python)
Requisitos: **Python 3.10+**

```bash
# Windows (PowerShell)
cd sprint3_pack
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install pandas numpy scikit-learn matplotlib

# macOS / Linux
cd sprint3_pack
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install pandas numpy scikit-learn matplotlib
```

---

## üóÑÔ∏è Parte 1 ‚Äî Banco de Dados

### 1.1 Diagrama ER (DER)
- Arquivo Mermaid: `db/erd.mmd` (abre em https://mermaid.live e exporta PNG, se quiser).
- Exportado via Oracle SQL Developer Data Modeler: **`db/ERD_sprint3_datasql.png`**.

**Entidades e campos (resumo funcional):**
- **SITE**: `site_id` (PK), `name`, `city`, `state`, `created_at`
- **ASSET**: `asset_id` (PK), `site_id` (FK‚ÜíSITE), `name`, `type`, `installed_at`
- **SENSOR_TYPE**: `sensor_type_id` (PK), `code` (UNIQUE), `description`, `unit`
- **SENSOR**: `sensor_id` (PK), `asset_id` (FK‚ÜíASSET), `sensor_type_id` (FK‚ÜíSENSOR_TYPE), `model`, `serial_number`, `installed_at`, `is_active` (CHECK IN 'Y','N')
- **READING**: `reading_id` (PK), `sensor_id` (FK‚ÜíSENSOR), `ts`, `value_num`, `quality` (CHECK IN 'OK','SUSPECT','MISSING')
- **ASSET_STATE**: `asset_state_id` (PK), `asset_id` (FK‚ÜíASSET), `ts`, `state` (CHECK IN 'normal','alerta','falha'), `note`

**Relacionamentos e √≠ndices:**
- SITE 1‚ÄîN ASSET; ASSET 1‚ÄîN SENSOR; SENSOR_TYPE 1‚ÄîN SENSOR; SENSOR 1‚ÄîN READING; ASSET 1‚ÄîN ASSET_STATE.
- √çndices essenciais: `READING(sensor_id, ts)` e `ASSET_STATE(asset_id, ts)` (consultas temporais).
- View utilit√°ria: `vw_sensor_latest` (√∫ltima leitura por sensor).

> **Por que assim?** Dados **brutos** ficam em `READING`; o **r√≥tulo agregado** por ativo/tempo fica em `ASSET_STATE`, o que facilita ML supervisionado e mant√©m a tabela de leituras limpa. `SENSOR_TYPE` normaliza unidade/descri√ß√£o.

### 1.2 Cria√ß√£o do schema
No **Oracle SQL Developer (IDE)**:
1. Abra `db/schema_oracle.sql` ‚Üí **Run Script (F5)**.
2. Abra `db/seed_data.sql` ‚Üí **Run Script (F5)** ‚Üí `COMMIT;`.

### 1.3 Valida√ß√µes (SQL)
Use como **evid√™ncias** (prints em `db/prints/`):
```sql
-- 1) Contagens (print: 01_counts.png)
SELECT
  (SELECT COUNT(*) FROM site)        AS sites,
  (SELECT COUNT(*) FROM asset)       AS assets,
  (SELECT COUNT(*) FROM sensor_type) AS sensor_types,
  (SELECT COUNT(*) FROM sensor)      AS sensors,
  (SELECT COUNT(*) FROM reading)     AS readings,
  (SELECT COUNT(*) FROM asset_state) AS asset_states
FROM dual;

-- 2) Sensores x Tipos (print: 02_sensors_map.png)
SELECT s.sensor_id, st.code AS sensor_code, st.unit, a.name AS asset_name
FROM sensor s
JOIN sensor_type st ON st.sensor_type_id = s.sensor_type_id
JOIN asset a        ON a.asset_id        = s.asset_id
ORDER BY s.sensor_id;

-- 3) √çndices (print: 03_indexes.png)
SELECT index_name, table_name, column_name, column_position
FROM user_ind_columns
WHERE table_name IN ('READING','ASSET_STATE')
ORDER BY table_name, index_name, column_position;

-- 4) PKs, FKs, CHECKs (prints: 04_constraints_pks.png, 05_constraints_fks.png, 06_constraints_checks.png)
-- PKs
SELECT table_name, constraint_name
FROM user_constraints
WHERE constraint_type = 'P'
  AND table_name IN ('SITE','ASSET','SENSOR_TYPE','SENSOR','READING','ASSET_STATE')
ORDER BY table_name;
-- FKs
SELECT c.table_name, c.constraint_name, r.table_name AS referenced_table
FROM user_constraints c
JOIN user_constraints r ON c.r_constraint_name = r.constraint_name
WHERE c.constraint_type = 'R'
  AND c.table_name IN ('ASSET','SENSOR','READING','ASSET_STATE')
ORDER BY c.table_name, c.constraint_name;
-- CHECKs
SELECT table_name, constraint_name, search_condition
FROM user_constraints
WHERE constraint_type = 'C'
  AND table_name IN ('SENSOR','READING','ASSET_STATE')
ORDER BY table_name, constraint_name;
```

**Opcional (07_view_latest.png):**
```sql
-- Insira 2 leituras no sensor TEMP e consulte:
-- SELECT s.sensor_id FROM sensor s JOIN sensor_type st ON st.sensor_type_id=s.sensor_type_id WHERE st.code='TEMP';
-- INSERT INTO reading(...) VALUES (...); COMMIT;
SELECT * FROM vw_sensor_latest WHERE sensor_id = <id_temp>;
```

---

## ü§ñ Parte 2 ‚Äî Machine Learning

### 2.1 Dataset
`data/processed/dataset_sprint3_multisensor.csv` (‚âà2.400 linhas) com:
```
timestamp, temp_c, humidity_pct, vibration_rms, motor_current_a,
light_lux, pressure_kpa, estado_operacional, temp_c_plus5min
```
> **Exig√™ncia atendida:** >500 leituras por sensor.

### 2.2 Classifica√ß√£o (entrega obrigat√≥ria)
```bash
# na raiz sprint3_pack, com o venv ativado
python src/ml_train_sprint3.py
```
**Sa√≠das esperadas em `results/`:**
- `metrics.txt` ‚Äî precis√£o/recall/F1 por classe e acur√°cia geral
- `confusion_matrix.png` ‚Äî visualiza√ß√£o dos acertos/erros por classe
- `sample_predictions.csv` ‚Äî amostras com predi√ß√µes

> **Justificativa do gr√°fico:** a **matriz de confus√£o** evidencia erros entre `normal/alerta/falha`, t√≠pica em uso industrial.  
> **Reprodutibilidade:** o script usa semente fixa (`random_state`) e `train_test_split` estratificado.

### 2.3 Regress√£o (over-delivery)
```bash
python src/ml_regression_sprint3.py
```
**Sa√≠das em `results/`:**
- `metrics_regression.txt` ‚Äî MAE e R¬≤
- `regression_real_vs_pred.png` ‚Äî s√©rie real vs predita (amostra)

> **Motiva√ß√£o:** prever temperatura em +5 min ajuda manuten√ß√£o preditiva e controle.

### 2.4 Pr√≥ximos passos (documentar)
- Janelas temporais (1/5/15 min), parti√ß√£o por data em `READING`, import√¢ncia de atributos/SHAP, views para BI/Power BI.

---

## üé¨ V√≠deo (at√© 5 min) ‚Äî roteiro sugerido
1. Contexto e objetivo (0:30)  
2. DER e normaliza√ß√£o (1:00‚Äì1:30)  
3. Pipeline: dados ‚Üí BD ‚Üí ML (1:00)  
4. Resultados: matriz de confus√£o (+ regress√£o) (1:00‚Äì1:30)  
5. Pr√≥ximos passos (0:30)

---

## ‚úÖ Checklist de Entreg√°veis (FIAP)
- [x] **DER** (PNG/SVG) + Mermaid  
- [x] **Script SQL** (`schema_oracle.sql`) + **seed**  
- [x] **CSV** do dataset  
- [x] **C√≥digo ML** (classifica√ß√£o) + (regress√£o opcional)  
- [x] **Gr√°ficos/prints**: `confusion_matrix.png`, `regression_real_vs_pred.png`, e `db/prints/*.png`  
- [x] **README** claro + link do v√≠deo (n√£o listado)

---

## Observa√ß√µes finais
- O modelo foi pensado para escalar: √≠ndices por tempo, checks de dom√≠nio e view de √∫ltimas leituras.  
- O pipeline de ML √© reproduz√≠vel e cobre **classifica√ß√£o** (exigida) e **regress√£o** (b√¥nus), refor√ßando a aplica√ß√£o pr√°tica em ambiente industrial.
